---
title: "시스템프로그래밍-파일 처리"
category:
  - system programming
tag:
  - system programming
  - linux
  - file
toc: true
toc_sticky: true
---

# 개요

## 저수준vs고수준 파일 처리

|저수준 파일 처리|고수준 파일 처리|
|---|---|
|파일기술자(file descriptor)를 사용하여 입출력|FILE 구조체를 사용하여 입출력|
|유닉스 계열에서만 사용 가능|C언어를 지원하는 모든 플랫폼에서 사용 가능|
|비직관적인 함수 형태|직관적이고 사용이 편리한 함수 형태|
|pread, pwrite를 통해 원자적(atomic) 실행 보장|라이브러리 레벨의 버퍼링 있음|

## 원자적(atomic) 실행

프로그래밍에서 원자적 실행이란 작동을 보장하면서 더 이상 나눌 수 없이 한 번에 실행되는 코드를 의미한다.<br>
파일 처리뿐만이 아니라 DB에서도 중요한 개념이다.

1) 파일에 입출력할 경우<br>
원자적 실행을 가능하게 하려면 pread, pwrite를 사용해야 한다. <br>
이들은 파일의 커서 위치를 사용하지 않고 절대적인 오프셋 주소를 사용하기 때문에 스레드에서 사용해도 안전해진다.

2) 파일이 아닌 파이프에 입출력할 경우<br>
read, write를 PIPE_BUF 이내의 길이로 입출력하는 경우에 원자성을 보장해준다.<br>
리눅스에서 PIPE_BUF는 4096이며 다른 유닉스는 이보다 커서 수십KB까지 되는 예도 있다. 이 크기는 페이지 단위에 영향을 받는 경우가 많아서 대부분 4096이나 그 배수가 사용된다.

## 파일 출력이 섞이지 않게 하는 방법

1) 출력 함수의 원자적 실행을 보장하는 기능을 사용하는 방법<br>
이 방법은 성능을 해치지도 않고 매우 편리하다. 다만 저수준의 파일 처리를 사용해야 한다는 단점이 생긴다.

1) 락(lock)을 이용해서 출력 과정을 보호하는 방법<br>
이 방법은 간단하지만, 성능을 해칠 수 있기 때문에 빈번한 출력에서는 쓰지 않는다

1) 직렬화를 이용해서 전문적으로 출력을 도맡아서 하는 프로세스나 스레드를 두는 방법.<br>
이 방법은 설계 과정이 복잡하고 무거워질 수 있지만, 신뢰성이 높고 응답이 좋은 장점이 있다.<br>
이외에 메모리 맵 파일(mmap)을 이용하여 메모리에 쓰고 파일로 동기화하는 방법도 있다.

## 형식화된 출력 기능

```c
/* 고수준 파일 처리 */
fprintf(fp, "counter : %d", i);
```

```c
/* 저수준 파일 처리 1 */
len = snprintf(buf, sizeof(buf), "counter : %d, i);
write(fd, buf,len);

/* 저수준 파일 처리 2 */
fprintf(fp, "counter : %d", i);
```

## inotify

 특정 파일에 접근, 읽기, 쓰기 등등 다양한 이벤트를 감시할 수 있다.<br>
 파일 관련 서비스를 해야 하는 프로그램에서 유용하게 사용된다.<br>
리눅스 전용 기능이므로 유닉스에는 지원되지 않는다.


# 파일 처리에 관련된 함수들  

이 함수들은 man fcntl 같이 man명령어로 상세정보 확인이 가능하다.

저수준 파일 처리 관련 함수

|open, openat<br>close, create|파일 열기, 파일기술자를 지정하여 파일 열기<br>닫기, 생성|
|fcntl|파일기술자 조작|
|fsync<br>fdatasync|파일 동기화<br>메타 정보를 제외한 동기화(access time 같은 inode 정보를 제외)|
|dup, dup2|파일기술자 복제|
|read, write|읽기, 쓰기|
|pread, pwrite|오프셋을 지정한 읽기, 쓰기 (시그널, 스레드 안전)|
|readv, writev|벡터단위 읽기 쓰기|
|dprintf|형식화된 문자열 출력|
|lseek|파일 위치 변경|
|truncate|파일 크기 변경|
|fdopen|파일기술자를 고수준 파일 처리의 스트림으로 변환|
|renameat|파일명 변경|
|glob|패턴 매칭되는 패스명 찾기|
|stat, fstat, fstatat|파일 메타 정보 읽기|

고수준 파일 처리 관련 함수 (stdio 맨페이지 참조)

|fopen, fclose|파일 스트림의 열기/닫기|
|freopen, fdopen|파일 스트림 다시 열기, 파일기술자로부터 열기|
|setvbuf, setbuf|스트림 버퍼 조작|
|fflush, fpurge|버퍼를 비움, 버퍼를 삭제|
|fread, fwrite|읽기, 쓰기|
|scanf 계열|형식화된 문자열 입력|
|getc 계열(gets, getw 포함)|버퍼 입력|
|printf 계열|형식화된 문자열 출력|
|putc 계열(puts, putw 포함)|
|fgetpos, fsetpos|파일 스트림의 위치 변경, 보고|
|fseek, ftell, rewind|파일 스트림의 위치 변경, 보고|
|clearerr, feof, ferror|파일 스트림 체크|
|ftruncate|파일 크기 변경|
|fileno|스트림을 파일기술자로 변환|
|fmemopen, open_memstream|메모리를 파일 스트림으로 열기(POSIX.1-2008에서 추가)|
|getline, getdelim|행단위, 구분자 단위로 읽기(POSIX.1-2008에서 추가)|
|getc_unlocked, getchar_unlocked, putc_unlocked, putchar_unlocked|getc, getchar, putc, putchar의 넌블럭킹 버전|

그 외의 파일 관련 함수들

|umask|umask 값 조정|
|mktemp|임시 파일 생성|
|remove, unlink|파일 삭제|
|link|링크 생성|
|mkdir, rmdir|디렉터리 생성, 삭제|
|opendir, closedir, fdopendir, dirfd|디렉터리 열기, 닫기|
|readdr, rewinddir, seekdir, telldir|디렉터리 읽기, 위치 변경/보고|
|scandir, alphasort|디렉터리 스캔|

# 저수준 파일 처리의 사용

~~~ c
fd = open(FILENAME, O_CREATE|O_TRUNC|O_WRONLY|O_APPEND, 0644);
~~~

open함수의 옵션 플래그들

- O_CREATE : 파일이 존재하지 않으면, 새로 생성
- O_TRUNC : 원래 파일의 내용을 모두 지우고 빈 파일을 연다
- O_WRONLY : 읽기 전용
- O_APPEND : 파일이 존재하는 경우, 뒤에 덧붙인다.
- O_EXCL : 열고자 하는 파일이 이미 존재하는 경우에 기존 파일을 백업 받고 새로운 파일을 열고자 하는 경우에 사용한다. 대부분 로그 파일과 같은 경우다.

O_EXCL플래그가 지정되면 열고자 하는 파일이 이미 존재하면 open이 실패하면 -1을 리턴하고 errnon는 EEXIST가 된다.

## 동기화된 I/O로 열기

저수준 파일 처리에서 설정할 수 있는 기능으로 OS의 I/O 처리와 레이턴시(latency)에 대한 개념을 알아야 한다.

동기화된 I/O를 사용하면 OS는 캐시된 데이터와 느린 디바이스를 최대한 동일하게 유지하려고 노력하게 된다. 하지만 응답성이 떨어지고 시스템의 성능은 떨어질 가능성이 높아지는 단점이 있다.

방법은 2가지가 있다.

- 수동으로 하는 경우

동기화가 필요한 시점에 fsync와 fdatasync 함수를 호출하면 된다.

- 입출력이 발생할 때마다 자동으로 동기화

open 함수로 파일을 열 때 O_SYNC나 O_DSYNC 옵션 플래그를 설정하면 된다. 이 두 개의 플래그의 차이점은 다음과 같이 부가적인 메타 데이터도 동기화 목록에 포함하느냐 아니냐의 차이이다.

- O_SYNC : 파일 내용과 메타 데이터 모두를 동기화한다.
- O_DSYNC : 메타 데이터를 빼고 동기화한다. (순수한 내용만 동기화하므로 가볍다)
- O_RSYNC : 읽기 작업에 대해서도 동기화된 I/O를 사용한다.

O_RSYNC는 기존의 동기화에 읽기 작업에 대한 동기화를 추가한다. 읽기 작업의 동기화란 디스크로부터 데이터를 읽어들일 때 밀린 쓰기 작업이 있다면 모두 완료한 뒤에 읽기 작업이 수행되도록 동기화를 진행한다.

따라서 O_RSYNC가 설정되면 지연된 쓰기 작업들이 완료된 뒤에야 읽기 작업이 수행되므로 캐시 효과를 볼 수 없어서 느려지는 단점이 있다. 이에 비해 O_RSYNC를 쓰지 않고 쓰기 작업에만 동기화도니 I/O를 사용하는 경우에는 읽기는 캐시를 사용하여 좀 더 빠르게 응답한다.

다음은 각각 네가지 형태의 동기화된 I/O 플래그를 적용한 예를 보여주고 있다.

~~~ c
fd = open(path, O_CREAT|O_WRONLY|O_SYNC, 0644); /* 동기화 I/O 사용 */
fd = open(path, O_CREAT|O_WRONLY|O_DSYNC, 0644); /* 메타 데이터를 제외한 동기화 */
fd = open(path, O_CREAT|O_RDWR|O_SYNC|O_RSYNC, 0644); /* 읽기 작업 동기화 추가 */
fd = open(path, O_CREAT|O_RDWR|O_DSYNC|O_RSYNC, 0644); /* 읽기 작업 동기화 추가 */
~~~

## 넌블록킹과 비동기적 I/O

둘 다 저수준 입출력을 사용하는 경우에 사용할 수 있다.

이 중에서 넌블록킹은 오히려 소켓 네트워킹에서 광범위하게 사용되므로 여기서 다루지 않고 6장의 네트워킹에서 다룰 것이다.

넌블록킹의 관련 기법은 소켓에 입출력하는 것과 일반 파일에 입출력하는 것이 크게 다르지 않다.

비동기적 I/O는 리얼타임 확장 표준에 포함되는 내용으로 AIO(Asynchronous I/O)라고 부른다. 이는 좀 더 고성ㄴ으 시스템에 적용하기 위한 기능으로서 기본적인 파일 처리를 다루는 부분에는 적합하지 않다고 판단되어 10장에서 다루도록 하겠다. 또한 10장에서는 넌블록킹과 비동기적 처리에 대한 차이점도 다루고 있으므로 꼭 숙지하면 좋을 것이다.

## close-on-exec로 열기

open을 호출할 때 _OCLOEXEC 플래그를 지정하면 colse-on-exec을 설정하게 된다. 이에 대해서는 exec를 다룰 때 설명했듯이 exec계열의 함수 때문에 다른 프로세스 이미지로 교체되면 자동으로 해당 파일 기술자를 닫도록 할 수 있다.

1장에서는 미리 open된 파일기술자에 적용하기 위해 fcntl의 FD_CLOEXEC플래그를 설정하도록 하였다. 하지만, open할 때 O_CLOEXEC플래그를 설정해두면 fcntl보다 편리하다.

참고로 open의 O_CLOEXEC 플래그는 2008년에 생겨다.

# 파일 닫기

파일을 쓰고 나면 항상 닫아줘야 한다. 힙 메모리를 사용하고 나면 free 해주는 것처럼 파일도 닫지 않으면 자원 누수가 발생한다.

특수한 경우를 제외하고는 모든 프로세스에는 최대 열수 있는 파일의 개수에 제한이 존재한다.

자원 제한에 대해서는 ulimit -a로 확인할 수 있다. 이준 open files 항목이 최대 파일 개수이다.

여기서 열수 있는 최대 파일 오픈 수(max open files)에 대한 설정은 unlimit -n 명령으로 확인할 수 있다.

## 파일 사용 패턴 조언
열린 파일기술자를 앞으로 순차적으로 읽을 것인지 아니면 랜덤하게 접근할 것인지 혹은 한 번만 쓰고 다시는 쓰지 않을 것인지를 알려주는 기능이다.

int posix_fadvise(int fd, off_t offset, off_t len, int advice);

순차적으로 접근하는 경우 : 시스템은 현재 읽은 데이터의 다음 데이터를 프리매칭해서 미리 가져오도록 한다. 이를 통해 최대한 레이턴시를 줄여주기 때문에 대용량 파일을 읽어들일 때 성능이 좋아진다.

한번만 읽고 더는 사용하지 않는 파일이라고 시스템에 조언해준다면 시스템은 해당 파일을 읽을 때 사용한 메모리를 퇴출하도록 캐시 정책에 반영할 수 있다. 이는 메모리를 좀 더 효율적으로 사용할 수 있게 한다.

# 고수준 파일 처리의 사용

고수준 파일 처리는 C언어 표준이고 추상화된 스트림에 더욱더 가까운 혀앹로 다뤄지기 때문에 운영체제 레벨의 작업은 몰라도 쉽게 이해할 수 있는 장점이 있다. 더군다나 다양한 포매팅이나 버퍼링을 제공하는 장점이 있다.

하지만 버퍼링은 사용자 변수와 버퍼 사이의 메모리 복사, 버퍼와 커널 사이의 복사까지 중복되므로 메모리 대역폭을 비효율적으로 사용하는 단점이 되기도 한다. 따라서 저수준 파일 처리보다 비효율적인 면이 있기에 리얼타임 시스템과 같이 응답성과 성능을 중시한다면 고수준 파일 처리를 최소한으로 사용하는 편이 좋다.

그리고 저수준도 일반적인 동기적 I/O보다는 비동기적I/O가 응답성과 성능 효율이 높기 대문에 성능만 따진다면 여러 선택이 존재한다. 그러나 성능에 대한 부분은 사용하는 메모리 형태 및 크기, 입출력 횟수에 따라서 달라지기 때문에 저수준과 고수준을 절대적으로 비교하기는 조금 무리가 따르기도 한다. 심지어 대부분의 작은 입출력에서는 고수준과 저수준이 별 차이가 없는 경우가 많다.

우선 고수준에서는 원자적 실행을 사용할 수 없다. 즉, 원자적 실행이나 병렬성 등과 같이 유닉스  표준에 영향을 미치는 부분은 모두 C언어 표준에서 제외되어 있다.

## FILE 구조체와 버퍼링

고수준 파일 처리에서는 FILE 구조체를 사용한다.

FILE 구조체 내부 구조는 임플리먼테이션별로 다르다.

C언어에서는 FILE 구조체를 통해서 얻어지는 파일 입출력 매개물을 파일 스트림이라 부르고 이는 가상화된 흐름을 표현하는 장치이다. 즉 데이터가 물처럼 수도관을 타고 흘러다니는 것이라고 이해하면 빠르다.

즉 스트림의 정의를 내리자면 연속된 공간에서의 가상의 데이터 흐름이라고 할 수 있다. 이는 어떤 데이터가 디스크 공간에 나뉘어 있거나 버퍼 메모리에 캐시되어 있다고 하더라도 사용자는 어디에 어떻게 있는지 상관할 필요없이 항상 하나의 통로를 통한 흐름으로 받아들일 수 있다.

이런 통일된 하나의 흐름으로 인식하면 매우 직관적이므로 쉽게 접근할 수 있게 된다. 더군다나 스트림은 파일의 상대적인 위치로 접근하거나 절대적인 오프셋 위치를 통해서 접근할 때도 직관적으로 계산할 수 있게 되므로 매우 편리해진다. 물론 이런 스트림을 이용하는 입출력은 유닉스의 저수준 파일 처리에서도 동일한 관점을 사용하기 때문에 추상화된 고수준과 크게 다를바는 없는데 이는 C언어가 준 영향 때문이라고 생각된다.

고수준 파일 입출력 예제

~~~ c
FILE *fp;
if((fp=fopen("streamfile.txt","w")) == NULL) {
  /*Error handling*/
}
...
fclose(fp);
~~~

고수준의 특징 : 형식화된 입출력과 버퍼링 기능

이 중에서 형식화된 출력은 dprintf계열 함수의 추가로 저수준에서도 가능하게 됐다.

그러나 라이브러리 레벨에서 사용되는 버퍼링은 고수준의 큰 특징 중 하나이다. 이를 제어하기 위해서 fflush와 setvbuf 함수가 제공된다.

fflush는 수동으로 버퍼를 비우는 작업을 하므로 강제로 출력하게 된다. setvbuf는 버퍼링을 제어하는 방법으로 기본적으로 완전 버퍼링(Fully buffered, block buffering)이 지저오디어 있다.

setvbuf(stdout, (char *)NULL, _IOLBF, 0);

위의 setvbuf 예는 라인 버퍼링(_IOLBF)을 지정하는 것으로서 개행문자(new line character)가 발견되면 버퍼를 자동으로 비운다. 즉 출력하면서 개행 문자가 나타나면 fflush를 자동으로 실행한다고 생각하면 이해가 빠르다. 이외에 _IONBF은 버퍼링을 하지 않는 것이고, _IOFBF를 사용하면 기본값인 완전 버퍼링을 의미한다.

- _IOFBF : 
- _IOLBF : 
- _IONBF : 

만일 setvbuf 정책보다 수동으로 버퍼를 비우는 것을 중시한다면 언제 비우는 것이 좋은지를 생각해 볼 필요가 있다.

너무 긴 버퍼링을 하면 반응속도나 버퍼 공간의 비효율적인 사용을 하게 되므로 적당한 시간이나 혹은 위와 같이 라인 버퍼링을 이요하거나 혹은 시스템에 맡겨버리거나 하는 방법이 좋다.

하지만 강제로 fflush를 실행하여 버퍼를 비우는 행위가 필요한 때가 있는데, 바로 fork나 exec 계열의 함수를 사용하는 경우이다. 물론 posix_spawn을 사용할 때도 마찬가지다. 이 경우에는 기존에 버퍼링된 데이터의 순서가 역전되거나 파괴될 수 있기에 미리 버퍼를 비우는 것이 안전하다.

## 바이너리 데이터 입출력

고수준 파일 처리에서

텍스트 형식의 데이터 입출력 : printf 계열, putc, puts, scanf, getc, fgets 등 다양한 함수
바이너리 데이터 입출력 : fwrite, fread 등 다양한 함수

바이너리 데이터 사용시 조심해야 할 것 : 구조체를 사용하면 팩화(packed)된 경우나 주소 경계가 정렬되어(aligned) 패딩(padding)이 발생하는 경우가 생길 수 있으므로 읽기/쓰기 시 정확한 위치 경계를 잡는 것이 중요하다.

이는 정적 캐스팅(static casting)으로 데이터를 읽어오거나 사용할 때 매우 중요한 문제를 일으킬 수 있다. 실제로 패딩을 고려하지 않은 바이너리 구조체 데이터를 타 플랫폼으로 이식하면 버스 에러 같은 문제점이 발생할 수 있다.

이런 문제를 해결하기 위해 mmap이나 네트워크 소켓을 통한 데이터 전송을 할 때는 XDR 규약(External Data Representation)을 지켜주는 것이 좋다.

# 저수준과 고수준 파일 처리의 혼용

이 둘을 혼용하면 어떤 문제가 생길 수 있는지, 무엇을 조심해야 하는지를 짚고 넘어가는 챕터다.

연결된 채널들(linked channels) : 한 개의 입출력 채널을 공유한 형태. 한 포인터의 현재 오프셋 위치를 lseek로 이동하면 공유된 모든 형태가 같이 변경된다.

그러나 fdopen(fd1, "a+")로 열게 되면 추가(append) 모드로 열리게 되는데, 이 경우에는 채널에 추가 모드의 플래그가 설정된다. 따라서 자동으로 모든 연결된 채널이 추가 모드로 작성하게 되며 lseek를 사용해도 항상 파일의 끝을 쓰게된다. 추가 모드에서는 파일을 읽으면 파일의 끝 다음에 있는 쓰레기 값들을 읽게 된다. fread의 리턴값을 살펴보면 읽은 데이터가 없으므로 0이 나오게 된다.

그러면 같은 파일을 여러 번 열어도 같은 일이 발생할까? 아니다.

연결된 채널을 사용하거나 저수준과 고수준 파일 처리를 혼용하더라도 매번 파일을 새로 열게 되면 각각의 파일은 독립된 채널들(independent channels)로 열리게 된다. 이렇게 독립된 채널들은 각각 따로 관리되므로 앞서 언급한 것과 같이 파일 위치 오프셋이나 옵션 플래그의 공유 문제는 발생하지 않는다. 하지만, 각각 버퍼가 존재하고 채널들을 생성하기 때문에 메모리 관련 오버헤드가 발생할 수 있다.

하지만 독립된 채널이라고 해도 여전히 나라의 파일에 여러 프로세스 나 스레드가 입출력하면 순서 역전 문제는 남는다. 이는 독립된 채널들이라고 하더라도 거의 동시에 동일 파일에 입출력한다면 실제 디스크로부터 읽거나 쓰는 시점이 미묘하게 역전될 가능성이 존재하기 때문이다. 더군다나 이런 역전 현상에는 운영체제의 스케줄링 영향을 받기 때문에 프로그래머가 예측할 수 없다. 물론 이를 막기 위해 파일 락이나 fflush 혹은 동기화된 I/O를 사용할 수도 있지만, 성능 면에서도 불이익이 생기고 문제도 백퍼센트 해결할 수 없는 경우가 많다. 

따라서 독립된 채널이든 연겯뢴 채널이든 간에 하나의 파일에 복수의 채널을 만드는 것은 지양해야 한다는 결론에 도달하게 된다. 앞서 팁에서 제공했듯이 쓰기 처리에 대한 부분은 직렬화를 시켜주는 것이 가장 성능과 신뢰성이 좋을 수 있다.

# 패딩(padding)/팩(pack)과 XDR

CPU는 메모리에 접근할 대 특정 바이트의 배수로 정렬된 주소로 접근하면 더 효율적으로 작동한다.

XDR(External Data Representation) : 주소 경계를 특정 단위의 배수로 정렬하기 위한 규칙

## XDR, RFC 1832

XDR 목적 : 서로 다른 아키텍처 간에 데이터 교환을 할 때 버스 오류 같은 현실적인 문제나 성능이 떨어지는 것을 최소화하기 위해 정의된 데이터 표현 방식

XDR 프로토콜은 특정 언어나 아키텍처에 종속적인 내용은 아니다.

통신을 위한 규칙 중에 이 책에서 설명하는 부분은 2가지 정도이다.

- 바이트 정렬

통신 데이터는 기본적으로 빅엔디안(big-endian)을 사용한다

- 메모리 정렬

즉 주소 경계에 대한 이야기로서 XDR은 기본 유닛의 크기를 4바이트 경계를 권고한다.

<br>

## 묵시적인 패딩과 명시적인 패딩

묵시적인 패딩 규칙은 아키텍처에 따라 다를 수 있다.

명시적인 패딩은 기준을 4나 8 바이트를 쓰는 것이 좋다.(4는 32bit, 8은 64bit)

명시적인 패딩은 코드의 성능을 최적화하기 위해 캐시 라인 크기에 맞춰서 정렬시키는 용도로도 사용된다. 예를 들어 라인의 크기가 64바이트라면 의도적으로 구조체의 크기를 64바이트나 128바이트 같이 캐시 라인 크기로 딱 떨어지도록 만든다.

이렇게 하면 멀티 스레드나 시그널 관련 프로그래밍에서 가짜 공유(false sharing)와 같은 캐시 미스를 상당수 줄일 수 있어서 성능 향상에 도움이 된다.

## 팩화 구조체

팩(pack)은 묵시적인 패딩을 제외하고 모든 구조체의 멤버를 붙이는 경우를 말한다.

이 기법은 하드웨어 레벨의 프로그래밍에서 사용하는 경우가 많으며 임플리먼테이션에 따라서 비표준화 예약어를 사용한다. 예를 들어 gcc에서 팩을 사용하려면 두 가지 방법이 제공된다.

- source code 내의 특정 struct에 __attribute__((packed)) 지시자를 사용
- gcc 컴파일시에 --pack-struct를 사용

__attribute__ 지시어는 정렬 기준을 지정하는 용도로 사용할 수도 있다. 예를 들어 __attribute__((aligned(#))) 지시자를 이용하면 # 바이트 단위로 정렬한다. 만일 64바이트 캐시 라인에 맞춰 64바이트 단위로 정렬하고 싶다면 #에 64를 넣으면 된다.

이외 GCC의 옵션들은 GCC 매뉴얼(http://gcc.gnu.org/onlinedocs)에서 찾아볼 수 있다.

## 호환성을 위한 설계

XDR의 메모리 정렬과 구조체의 패딩은 아키텍처에 관련되기 때문에 서로 다른 시스템이라면 필히 고민해야 하는 것들이다. 또한 프로그래밍 언어별로 구조체를 지원하는 경우도 있고 정수형 타입도 지원 범위가 다를 수 있기 때문에 자료를 교환할 대는 아키텍처 외에 개발에 사용되는 언어도 생각해야 한다.

그런데 XDR은 이런 ㅎ ㅗ환성에 큰 걸림돌이 되기 때문에 약간의 오버헤드는 있지만 가장 확실한 방법으로 텍스트 기반의 통신이 있다. 텍스트는 바이트 단위이므로 패딩과 정렬에서 벗어날 수 있기 때문이다.

예를 들어 자바에서 구조체나 멀티 바이트 데이터 타입을 처리하려면 바이트 단위로 읽어서 변환해야 하므로 패딩 처리를 하다가 오류가 생길 가능성이 있다. 따라서 굳이 구조체를 통해서 통신한다면 묵시적인 패딩이 존재하는지 확인 절차를 거쳐야 한다.

# 대용량 파일 지원(LFS)

일반적으로 파일을 다루는 함수들은 32bit 머신의 어드레싱 공간 제한인 2GiB 영역까지만 지원한다.

따라서 대용량 파일을 다루기 위해서는 LFS에 대해서 알아둬야 한다.

다만, 64bit 시스템은 기본적으로 대용량 파일을 사용하므로 해당 사항이 없다.

LFS를 사용하려면 2가지를 체크해야봐야 한다. 먼저 파일 시스템 포맷이 LFS를 지원해야만 하고 그 다음으로는 라이브러리(glibc)가 LFS를 지원해야 한다.

리눅스의 ext2, ext3, ext4는 다행히도 LFS를 지원한다. 또한, glibc는 2.1.3 이상이라면 LFS 지원이 된다. 

이 두 가지가 만족한다면 두 가지 방식으로 64bit LFS를 사용할 수 있다. 그러면 왜 두가지 방식인가? 그것은 기존 32bit 파일 시스템과 호환성 때문이다.

## 32bit와 64bit 파일 관련 함수를 따로 사용하기

기존의 open, read, write, lseek 등의 파일 관련 함수는 그대로 32bit의 한계를 가지도록 두고 새로운 open64, read64, write64, lseek64와 같은 64bit 버전의 함수를 따로 쓰는 방식이다. 이 방식을 사용하기 위한 방법과 32bit 버전과의 차이점을 보도록 한다.

- off_t는 32bit 한계를 가지고 off64_t는 64bit 한계를 가지므로 따로 사용할 것.
- 저수준 입출력은 open64, read64, write64, lseek64 등을 사용하고 고수준 입출력의 경우는 fopen64 ... 처럼 뒤에 64가 추가된 함수들을 통해 64bit LFS를 사용한다.

이 방식을 사용하기 위한 매크로 정의

~~~
#define _LARGEFILE_SOURCE
#define _LARGEFILE64_SOURCE

gcc ...(생략) -D_LARGEFILE_SOURCE -D_LARGEFILE64_SOURCE ...(생략)
~~~

32/64비트를 동시 사용하는 LFS 매크로

|_LARGEFILE_SOURCE|ftello와 fseeko 함수를 사용 가능해진다.|
|_LARGEFILE64_SOURCE|함수명 뒤에 64가 붙은 64bit 버전의 함수와 open 함수에서 대용량 파일 가능 플러그인 O_LARGEFILE를 사용가능케 한다.|

## 32bit 함수를 64bit로 모두 변환하기

이 방식이 가장 간단하게 LFS를 지원하는 방식이다.

기존의 open, read, write 함수를 전혀 수정할 필요 없이 컴파일할 때 모두 64bit 버전으로 변환된다. 따라서 open을 사용해도 _FILE_OFFSET_BITS=64 매크로를 통해 자동으로 open64로 확장된다. 마찬가지로 off_t는 off64_t가 된다는 점에서 따로 코딩할 필요가 없어진다.

~~~
#define _LARGEFILE_SOURCE
#define _FILE_OFFSET_BITS 64

gcc ...(생략) -D_LARGEFILE_SOURCE -D_FILE_OFFSET_BITS=64 ...(생략)
~~~

|_LARGEFILE_SOURCE|ftello와 fseeko 함수를 사용가능해진다.|
|_FILE_OFFSET_BITS=64|32 bit 기준의 파일 관련 함수와 변수 타입이 64bit 버전으로 변경됨. off_t 타입도 자동으로 off64_t로 교체됨.|

각 플랫폼이나 파일 시스템별로 LFS 지원 여부와 그 한계는 Andreas Jaeger <aj@suse.de>의 리눅스의 LFS에 대한 글에 정리되어 있으니 참고하도록 한다. http://www.suse.de/~aj/linux_lif.html

마지막으로 ftello와 fseeko는 SUSv2(UNIX98)에서 승인된 함수이므로 glibc에서 이를 다루려면 이 표준에 맞도록 매크로를 선언해주어야 한다. UNIX98은 _XOPEN_SOURCE가 500인 경우를 의미하므로 500이나 그 이상을 지정해야만 한다. 이에 대한 내용은 매뉴얼 페이지의 "Confirming to"란에 나와 있다고 머리말에 적어둔 것을 잊지 말기 바란다.

## GiB와 GB의 차이

kibi, mebi, gibi, tebi, pebi, exbi는 IEC에서 제정한 2의 승수에 대한 명칭이다. (1998년) 2의 10승씩 올라가므로 kibi는 2&10, mebi는 2^20승을 의미한다. 이들 2승수 표기는 Ki, Mi, Gi, Ti, Pi, Ei로 표기하며 10승수 표기인 K, M, G ... 등과는 표기부터 서로 구별된다. 예로 K는 1000이고 Ki는 1024이다. 따라서 하드웨어는 일반적으로 10의 승수로 표기되고 소프트웨어에서는 2의 승수로 표기되므로 수치에 차이가 생길 수 있다.

이 부분 매 번 궁금하던 건데, 나중에 포스트 정리할 때 제대로 정리해야 겠다.












